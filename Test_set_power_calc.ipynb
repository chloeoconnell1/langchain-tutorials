{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu4paQG8N8Uggbzc332T9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chloeoconnell1/langchain-tutorials/blob/main/Test_set_power_calc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_RCumnT84qo",
        "outputId": "b785e8fd-6e4b-4a10-a144-8f016e05ecdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test size 50: Power = 0.262, Mean F1 diff = 0.106\n",
            "Test size 100: Power = 0.421, Mean F1 diff = 0.120\n",
            "Test size 150: Power = 0.550, Mean F1 diff = 0.143\n",
            "Test size 200: Power = 0.658, Mean F1 diff = 0.160\n",
            "Test size 300: Power = 0.738, Mean F1 diff = 0.158\n",
            "Test size 400: Power = 0.805, Mean F1 diff = 0.158\n",
            "Test size 500: Power = 0.842, Mean F1 diff = 0.164\n",
            "Test size 550: Power = 0.848, Mean F1 diff = 0.162\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Constants\n",
        "positive_rate = 0.015      # 1.5% of test set is positive\n",
        "n_trials = 1000\n",
        "alpha = 0.05\n",
        "\n",
        "def generate_predictions(y_true, precision, recall):\n",
        "    \"\"\"Simulate predictions given precision and recall on a fixed y_true.\"\"\"\n",
        "    y_pred = []\n",
        "\n",
        "    for y in y_true:\n",
        "        if y == 1:\n",
        "            y_pred.append(1 if np.random.rand() < recall else 0)\n",
        "        else:\n",
        "            # Derive false positive rate from precision\n",
        "            # precision = TP / (TP + FP) => FP = TP * (1 - prec) / prec\n",
        "            # To get a false positive rate we can use:\n",
        "            fp_rate = (1 - precision) / precision * positive_rate / (1 - positive_rate)\n",
        "            y_pred.append(1 if np.random.rand() < fp_rate else 0)\n",
        "\n",
        "    return np.array(y_pred)\n",
        "\n",
        "def simulate_power(n, p1, r1, p2, r2):\n",
        "    f1_a = []\n",
        "    f1_b = []\n",
        "\n",
        "    for _ in range(n_trials):\n",
        "        # Shared true labels\n",
        "        y_true = np.random.choice([1, 0], size=n, p=[positive_rate, 1 - positive_rate])\n",
        "        y_pred_a = generate_predictions(y_true, p1, r1)\n",
        "        y_pred_b = generate_predictions(y_true, p2, r2)\n",
        "\n",
        "        f1_a.append(f1_score(y_true, y_pred_a, zero_division=0))\n",
        "        f1_b.append(f1_score(y_true, y_pred_b, zero_division=0))\n",
        "\n",
        "    # Paired t-test (more appropriate since each model sees the same data)\n",
        "    _, p_val = ttest_rel(f1_a, f1_b)\n",
        "    power = np.mean(np.array(f1_b) > np.array(f1_a)) * (p_val < alpha)\n",
        "    mean_diff = np.mean(np.array(f1_b) - np.array(f1_a))\n",
        "    return power, mean_diff\n",
        "\n",
        "# Try different test set sizes\n",
        "for n in [50, 100, 150, 200, 300, 400, 500, 550]:\n",
        "    power, diff = simulate_power(\n",
        "        n=n,\n",
        "        p1=0.3, r1=0.3,    # Model A\n",
        "        p2=0.45, r2=0.45   # Model B\n",
        "    )\n",
        "    print(f\"Test size {n}: Power = {power:.3f}, Mean F1 diff = {diff:.3f}\")\n",
        "\n",
        "    # 0.015 prevalence is likely reasonable for all risk factors except:\n",
        "      # Placenta accreta\n",
        "      # Chorio - however this is likely underreported by nursing risk assessments\n",
        "      # Low platelets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKVLZXZ985rD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}